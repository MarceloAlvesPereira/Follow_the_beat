{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1fc4610",
   "metadata": {},
   "source": [
    "https://developer.spotify.com/documentation/web-api/\n",
    "\n",
    "https://developer.spotify.com/\n",
    "\n",
    "https://developer.spotify.com/dashboard/login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ff3b63",
   "metadata": {},
   "source": [
    "**Objectives:**\n",
    "- recommend the next song for an user base on his current playlist\n",
    "\n",
    "**Assumptions:**\n",
    "- tracks of a given playlist are the favorite songs of the user\n",
    "\n",
    "**Methodology:**\n",
    "1. Collaborative filtering\n",
    "2. Initial sample for each user will take 70% of the tracks in the playlist (check if the sorting of the musics in the playlist has any information - date of inclusion, user sorting, etc) and then use the remaining 30% of the tracks as test.\n",
    "3. **If we have time:** Hybrid model by adding *Content based filtering* for playlists with few tracks\n",
    "    - Track features: genre, time, top_track, etc.\n",
    "**Concerns:**\n",
    "- cold start: playlists with few tracks\n",
    "- rare tracks: treatment to be applied to the tracks with low frequency on the database\n",
    "- only positive rating: we will have only tracks that the user liked, we do not have any data about tracks that they did not like.\n",
    "\n",
    "\n",
    "**Python Libraries:**\n",
    "- Sagemaker\n",
    "- Elasticsearch\n",
    "- PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dd7a96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T18:00:34.723709Z",
     "start_time": "2021-10-16T18:00:34.714733Z"
    }
   },
   "outputs": [],
   "source": [
    "# Default libraries: pandas, numpy\n",
    "# import beakerx\n",
    "import cProfile\n",
    "import collections\n",
    "import datetime\n",
    "\n",
    "import feather\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# import urbangrammar_graphics as ugg\n",
    "\n",
    "from IPython.display import Markdown as md\n",
    "from collections import Counter\n",
    "from clustergram import Clustergram\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from itertools import groupby\n",
    "\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_validate, learning_curve, GridSearchCV, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import scale, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "# plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f332f6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T18:00:36.150638Z",
     "start_time": "2021-10-16T18:00:36.137674Z"
    }
   },
   "outputs": [],
   "source": [
    "def single_list(my_list):\n",
    "    single = []\n",
    "    for e in my_list:\n",
    "        single.extend(e)\n",
    "    return single\n",
    "\n",
    "def single_list_nested(my_list):\n",
    "    single = []\n",
    "    for e in my_list:\n",
    "        for a in e:\n",
    "            single.extend(a)\n",
    "    return single\n",
    "\n",
    "def sorted_list(xs):\n",
    "    counts = collections.defaultdict(int)\n",
    "    for x in xs:\n",
    "        counts[x] += 1\n",
    "    return sorted(counts.items(), reverse=True, key=lambda tup: tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd20da23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T18:00:38.418687Z",
     "start_time": "2021-10-16T18:00:37.825756Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = os.getcwd() + '\\\\data\\\\external\\\\raw_data.pkl'\n",
    "df = pd.read_pickle(data_path)\n",
    "print(df.info())\n",
    "\n",
    "# total = 0\n",
    "# idx = 0\n",
    "# while total < 10000:\n",
    "# #     print(len(df.iloc[idx, 2]))\n",
    "    \n",
    "#     total = total + len(df.iloc[idx, 2])\n",
    "#     idx = idx + 1\n",
    "# #     len(df.iloc[0:n, :])\n",
    "# print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166e995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def playlist_to_row(playlist, track_matrix):\n",
    "    for col_track in playlist:\n",
    "                if col_track is not None:\n",
    "                    col = s_tracks_id.index(col_track)\n",
    "                    track_matrix[row, col] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86026cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking(df,id_column):\n",
    "    single_list_temp = single_list(df[id_column])\n",
    "    data = {id_column: single_list_temp}\n",
    "    aux_df = pd.DataFrame(data)\n",
    "    \n",
    "    name = id_column.replace('_id','_count')\n",
    "    ranked_sorted = aux_df.groupby([id_column]).agg(\n",
    "        temp_count=pd.NamedAgg(column=id_column, aggfunc=\"count\")\n",
    "    )\n",
    "    ranked_sorted = ranked_sorted.rename(columns={'temp_count': name})\n",
    "    ranked_sorted = ranked_sorted.sort_values(name,ascending=False)\n",
    "    return ranked_sorted\n",
    "# ranking(df_test,'tracks_id')\n",
    "# print(tracks_rank)\n",
    "\n",
    "def top(ranked,n):\n",
    "    top_n = ranked.iloc[:n]\n",
    "    \n",
    "    return top_n\n",
    "# tracks_rank = ranking(df_test,'tracks_id')\n",
    "# top(tracks_rank,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24639d5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T18:13:06.201988Z",
     "start_time": "2021-10-16T18:00:39.978879Z"
    }
   },
   "outputs": [],
   "source": [
    "# matrix track x track\n",
    "# idx = 131\n",
    "# df_test = df.iloc[0:idx, :]\n",
    "df_test = df\n",
    "\n",
    "print(df_test.info())\n",
    "\n",
    "s_tracks_id = single_list(df_test['tracks_id'])\n",
    "data = {'tracks_id': s_tracks_id}\n",
    "df_track = pd.DataFrame(data)\n",
    "\n",
    "tracks_rank = df_track.groupby(['tracks_id']).agg(\n",
    "    tracks_count=('tracks_id','count')\n",
    "    )\n",
    "tracks_rank = tracks_rank.sort_values('tracks_count',ascending=False)\n",
    "\n",
    "# tracks_rank\n",
    "\n",
    "\n",
    "# s_tracks_id = list(set(single_list(df_test['tracks_id'])))\n",
    "# s_tracks_id = list(set(single_list(df['tracks_id'])))\n",
    "s_tracks_id = list(tracks_rank.index)\n",
    "# print(len(s_tracks_id))\n",
    "# s_tracks = single_list(df_test['tracks'])\n",
    "\n",
    "shape = [len(s_tracks_id),len(s_tracks_id)]\n",
    "track_matrix = np.zeros(shape, dtype=int, order='C')\n",
    "\n",
    "for i, row_track in enumerate(s_tracks_id):\n",
    "    row = s_tracks_id.index(row_track)\n",
    "    if i != row: print(\"i: \" + str(i) + \": \" + row_track), print()\n",
    "    \n",
    "    \n",
    "    for playlist in df_test['tracks_id']:\n",
    "        try:\n",
    "            check = playlist.index(row_track)\n",
    "        except ValueError:\n",
    "            check = -1\n",
    "        if check >= 0:\n",
    "            for col_track in playlist:\n",
    "                if col_track is not None:\n",
    "                    col = s_tracks_id.index(col_track)\n",
    "#                     print(col_track  + \" - \" + str(col))\n",
    "#                     tr = df_test['tracks'][n][col]\n",
    "#                     print(\"track: \" + str(n) + \": \" + col_track + \" - col_match:\" + str(col) + \": \") # + tr)\n",
    "                    track_matrix[row, col] += 1\n",
    "# print(track_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f1dcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T17:18:57.345660Z",
     "start_time": "2021-10-16T17:18:57.334689Z"
    }
   },
   "outputs": [],
   "source": [
    "track_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5375d025",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T17:35:17.867365Z",
     "start_time": "2021-10-16T17:35:02.213393Z"
    }
   },
   "outputs": [],
   "source": [
    "# compare principal diagonal versus the counting of each track\n",
    "# print(tracks_rank)\n",
    "n_rows, n_cols = track_matrix.shape\n",
    "for i in range(0,n_rows):\n",
    "    for j in range(i,n_cols):\n",
    "        if track_matrix[i][j] != track_matrix[j][i]:\n",
    "            print(\"Difference: \" + str(i) + \",\" + str(j))\n",
    "# for i, in enumerate(track_matrix):\n",
    "#     for j,col in enumerate(row):\n",
    "#         if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8120758f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T17:19:03.378110Z",
     "start_time": "2021-10-16T17:19:03.254239Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if the matrix is symmetrical\n",
    "column_sums = track_matrix.sum(axis=0)\n",
    "row_sums = track_matrix.sum(axis=1)\n",
    "\n",
    "print(tracks_rank)\n",
    "print(column_sums)\n",
    "print(row_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff1c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(row_sums) != len(column_sums):\n",
    "    print(\"error row * col\")\n",
    "\n",
    "for i in range(0,len(row_sums))\n",
    "     if tracks_rank[i] != column_sums[i]:\n",
    "            print(\"Difference: \" + str(i) + \",\" + str(j))\n",
    "print(tracks_rank)\n",
    "print(column_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13172ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the sum of rows matches the sum of the columns\n",
    "column_sums = track_matrix.sum(axis=0)\n",
    "row_sums = track_matrix.sum(axis=1)\n",
    "\n",
    "print(column_sums)\n",
    "print(row_sums)\n",
    "\n",
    "if len(column_sums) != len(row_sums):\n",
    "    print(\"error col * row\")\n",
    "\n",
    "for i in range(0,len(row_sums)):\n",
    "     if row_sums[i] != column_sums[i]:\n",
    "            print(\"Difference: \" + str(i) + \",\" + str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f269fa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T17:19:11.441939Z",
     "start_time": "2021-10-16T17:19:10.821999Z"
    }
   },
   "outputs": [],
   "source": [
    "# min_max = MinMaxScaler()\n",
    "# tracks_rank['count_scaled'] = min_max.fit_transform(tracks_rank[[\"tracks_count\"]])\n",
    "\n",
    "track_normed_by_col = track_matrix / track_matrix.max(axis=0)\n",
    "track_normed_by_row = track_matrix / track_matrix.max(axis=1)\n",
    "\n",
    "delta = track_normed_by_col - track_normed_by_row\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578fa0f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T17:19:16.035086Z",
     "start_time": "2021-10-16T17:19:14.863228Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "plt.imshow(-track_matrix, interpolation='nearest', cmap=plt.cm.gist_heat)\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f7920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T01:33:19.681758Z",
     "start_time": "2021-10-16T01:33:19.651104Z"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "SPOTIPY_API = os.getenv('SPOTIPY_API')\n",
    "SPOTIPY_API_KEY = os.getenv('SPOTIPY_API_KEY')\n",
    "scope=''\n",
    "\n",
    "# https://spotipy.readthedocs.io/en/latest/#\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=SPOTIPY_API, client_secret=SPOTIPY_API_KEY)\n",
    "\n",
    "# help(sp)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d04600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T21:25:55.193210Z",
     "start_time": "2021-10-15T21:25:53.905Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_playlist_detail(user_id, playlist_id):\n",
    "    l_artists = []\n",
    "    l_albums = []\n",
    "    l_tracks = []\n",
    "    l_popularity = []\n",
    "    l_artists_id = []\n",
    "    l_albums_id = []\n",
    "    l_tracks_id = []\n",
    "    \n",
    "    playlist = sp.user_playlist(user_id, playlist_id)\n",
    "    \n",
    "    for item in playlist['tracks']['items']:\n",
    "        group = []\n",
    "        group_id = []\n",
    "        for artist in item['track']['album']['artists']:\n",
    "            group.append(artist['name'])\n",
    "            group_id.append(artist['id'])\n",
    "        l_artists.append(group)\n",
    "        l_artists_id.append(group_id)\n",
    "        l_albums.append(item['track']['album']['name'])\n",
    "        l_tracks.append(item['track']['name'])\n",
    "        l_popularity.append(item['track']['popularity'])\n",
    "        \n",
    "        l_albums_id.append(item['track']['album']['id'])\n",
    "        l_tracks_id.append(item['track']['id'])\n",
    "        \n",
    "    return user_id, playlist_id, l_artists, l_albums, l_tracks, l_popularity, l_artists_id, l_albums_id, l_tracks_id;\n",
    "\n",
    "# user_id, playlist_id, l_artists, l_albums, l_tracks, l_popularity, l_artists_id, l_albums_id, l_tracks_id = get_playlist_detail('spotify', '37i9dQZF1DWXjlWxUbm84A')\n",
    "# user_id, playlist_id, l_artists, l_albums, l_tracks, l_popularity, l_artists_id, l_albums_id, l_tracks_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac0a23e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T03:08:23.508721Z",
     "start_time": "2021-10-13T03:08:21.354379Z"
    }
   },
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "data_path = os.getcwd() + '\\\\data\\\\external\\\\raw_1_uid_pid.pkl'\n",
    "if os.path.exists(data_path):\n",
    "    data_path_2 = os.getcwd() + '\\\\data\\\\external\\\\raw_2_playlists.pkl'\n",
    "    if not(os.path.exists(data_path_2)):\n",
    "        with open(data_path, 'rb') as f:\n",
    "            uid_pid_raw = pickle.load(f)\n",
    "else:\n",
    "    n = 950 # max = 950\n",
    "    p_limit = 50 # limit of playlists max = 50\n",
    "\n",
    "    # list of all user ids (UID) and playlist ids (PID)\n",
    "    uid_pid_raw = []\n",
    "    \n",
    "    for y in range(2018,2022,1):\n",
    "        txt = 'year:' + str(y)\n",
    "        for i in range(0,n,1):\n",
    "            if i % 100 == 0: print(txt + ': ' + str(i) + '/' + str(n))\n",
    "            uid_pid = sp.search(q=txt, type='playlist', limit=p_limit, offset=i) #,market='US'\n",
    "            uid_pid_raw.append(uid_pid)\n",
    "    # Save the data\n",
    "    with open(data_path, 'wb') as f:\n",
    "        pickle.dump(uid_pid_raw, f)\n",
    "\n",
    "\n",
    "t_end = time.time()\n",
    "np.abs(t_start - t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2797881",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T16:35:37.260142Z",
     "start_time": "2021-12-04T16:35:37.048266Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_path, 'wb') as f:\n",
    "        pickle.dump(uid_pid_raw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6614db7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-13T03:26:38.441Z"
    }
   },
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "data_path = os.getcwd() + '\\\\data\\\\external\\\\raw_2_playlists.pkl'\n",
    "if os.path.exists(data_path):\n",
    "#     print(\"Loading data...\")\n",
    "#     data_path_2 = os.getcwd() + '\\\\data\\\\external\\\\split_1_playlists.pkl'\n",
    "#     if not(os.path.exists(data_path_2)):\n",
    "#         with open(data_path, 'rb') as f:\n",
    "#             playlist_raw = pickle.load(f)\n",
    "else:\n",
    "    print(\"Requesting playlists - Spotipy\")\n",
    "#     playlist_raw = []\n",
    "\n",
    "#     for i, result in enumerate(uid_pid_raw):\n",
    "#         print(i)\n",
    "#         if i % 100 == 0: print(i)\n",
    "#         for user in result['playlists']['items']:\n",
    "#             pid = user['id']\n",
    "#             uid = user['owner']['id']\n",
    "#             try:\n",
    "#                 playlist = sp.user_playlist(user['id'],user['owner']['id'])\n",
    "#                 playlist_raw.append(playlist)\n",
    "#             except:\n",
    "#                 print(uid + \" \" + pid)\n",
    "                   \n",
    "   # Save the data\n",
    "#     with open(data_path, 'wb') as f:\n",
    "#         pickle.dump(playlist_raw, f)\n",
    "\n",
    "t_end = time.time()\n",
    "np.abs(t_start - t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd22bda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T01:18:05.085068Z",
     "start_time": "2021-10-15T01:18:04.566607Z"
    }
   },
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "data_path = os.getcwd() + '\\\\data\\\\external\\\\raw_data.pkl'\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_pickle(data_path)\n",
    "else:\n",
    "#     print('ops')\n",
    "    n = 50\n",
    "    p_limit = 50 # limit of playlists max = 50\n",
    "\n",
    "    user_id = []\n",
    "    playlist_id = []\n",
    "    artists = []\n",
    "    albums = []\n",
    "    tracks = []\n",
    "    popularity = []\n",
    "    artists_id = []\n",
    "    albums_id = []\n",
    "    tracks_id = []\n",
    "\n",
    "    for i in uid_pid:\n",
    "        if i-1 % 100 == 0: print(i)\n",
    "        for user in result['playlists']['items']:\n",
    "            pid = user['id']\n",
    "            uid = user['owner']['id']\n",
    "#                 user_id.append(uid)\n",
    "#                 playlist_id.append(pid)\n",
    "            p_user_id, p_playlist_id, p_artists, p_albums, p_tracks, p_popularity, p_artists_id, p_albums_id, p_tracks_id = get_playlist_detail(uid,pid)\n",
    "\n",
    "            user_id.append(p_user_id)\n",
    "            playlist_id.append(p_playlist_id)\n",
    "            artists.append(p_artists)\n",
    "            albums.append(p_albums)\n",
    "            tracks.append(p_tracks)\n",
    "            popularity.append(p_popularity)\n",
    "            artists_id.append(p_artists_id)\n",
    "            albums_id.append(p_albums_id)\n",
    "            tracks_id.append(p_tracks_id)\n",
    "#             if i-1 % 100 == 0: print('tot:' + str(len(playlist_id)))\n",
    "\n",
    "    # intialise data of lists.\n",
    "    data = {\n",
    "        'user_id': user_id,\n",
    "        'playlist_id': playlist_id,\n",
    "        'tracks_id': tracks_id,\n",
    "        'tracks': tracks,\n",
    "        'popularity': popularity,\n",
    "        'artists_id': artists_id,\n",
    "        'artists': artists,\n",
    "        'albums_id': albums_id,\n",
    "        'albums': albums\n",
    "    }\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    df.head()\n",
    "\n",
    "    # Save the data\n",
    "    df.to_pickle(data_path)\n",
    "\n",
    "t_end = time.time()\n",
    "np.abs(t_start - t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dade6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T01:18:13.795135Z",
     "start_time": "2021-10-15T01:18:13.544330Z"
    }
   },
   "outputs": [],
   "source": [
    "s_tracks_id = single_list(df['tracks_id'])\n",
    "s_tracks = single_list(df['tracks'])\n",
    "s_popularity = single_list(df['popularity'])\n",
    "\n",
    "s_artists = single_list_nested(df['artists'])\n",
    "s_artists_id = single_list_nested(df['artists_id'])\n",
    "\n",
    "s_albums = single_list(df['albums'])\n",
    "s_albums_id = single_list(df['albums_id'])\n",
    "\n",
    "data = {\n",
    "    'tracks_id': s_tracks_id,\n",
    "    'tracks': s_tracks,\n",
    "    'popularity': s_popularity\n",
    "}\n",
    "df_track = pd.DataFrame(data)\n",
    "# print(df_track.head())\n",
    "\n",
    "data = {\n",
    "    'artists_id': s_artists_id,\n",
    "    'artists': s_artists\n",
    "}\n",
    "df_artist = pd.DataFrame(data)\n",
    "# print(df_artist.head())\n",
    "\n",
    "\n",
    "data = {\n",
    "    'albums_id': s_albums_id,\n",
    "    'albums': s_albums\n",
    "}\n",
    "df_album = pd.DataFrame(data)\n",
    "# print(df_album.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa1148f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T01:18:16.812057Z",
     "start_time": "2021-10-15T01:18:16.664424Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks_rank = df_track.groupby(['tracks_id','tracks']).agg(\n",
    "    popularity=('popularity','max'),\n",
    "    tracks_count=('tracks_id','count')\n",
    "    )\n",
    "\n",
    "min_max = MinMaxScaler()\n",
    "tracks_rank['count_scaled'] = min_max.fit_transform(tracks_rank[[\"tracks_count\"]])\n",
    "\n",
    "tracks_rank[\"rank\"] = tracks_rank['tracks_count'].rank(method='average',ascending=False)\n",
    "\n",
    "tracks_rank = tracks_rank.sort_values('tracks_count',ascending=False)\n",
    "\n",
    "tracks_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea81952",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T01:18:17.188674Z",
     "start_time": "2021-10-15T01:18:17.070904Z"
    }
   },
   "outputs": [],
   "source": [
    "album_rank = df_album.groupby(['albums_id','albums']).agg(album_count=('albums_id','count'))\n",
    "\n",
    "min_max = MinMaxScaler()\n",
    "album_rank['count_scaled'] = min_max.fit_transform(album_rank[[\"album_count\"]])\n",
    "\n",
    "album_rank[\"rank\"] = album_rank['album_count'].rank(method='average',ascending=False)\n",
    "\n",
    "album_rank = album_rank.sort_values('album_count',ascending=False)\n",
    "\n",
    "album_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2cfd57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T01:18:18.013040Z",
     "start_time": "2021-10-15T01:18:17.895790Z"
    }
   },
   "outputs": [],
   "source": [
    "df_artist.head\n",
    "artist_rank = df_artist.groupby(['artists_id','artists']).agg(artist_count=('artists_id','count'))\n",
    "\n",
    "min_max = MinMaxScaler()\n",
    "artist_rank['count_scaled'] = min_max.fit_transform(artist_rank[[\"artist_count\"]])\n",
    "\n",
    "artist_rank[\"rank\"] = artist_rank['artist_count'].rank(method='average',ascending=False)\n",
    "\n",
    "artist_rank = artist_rank.sort_values('artist_count',ascending=False)\n",
    "\n",
    "artist_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f65e94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T21:43:09.090713Z",
     "start_time": "2021-10-12T21:43:09.076753Z"
    }
   },
   "outputs": [],
   "source": [
    "# tracks_cartesian = []\n",
    "# for element in itertools.product(s_tracks_id,s_tracks_id):\n",
    "#     tracks_cartesian.append(element)\n",
    "\n",
    "# https://stackoverflow.com/questions/11144513/cartesian-product-of-x-and-y-array-points-into-single-array-of-2d-points\n",
    "# def cartesian_product(*arrays):\n",
    "#     la = len(arrays)\n",
    "#     dtype = np.result_type(*arrays)\n",
    "#     arr = np.empty([len(a) for a in arrays] + [la], dtype=dtype)\n",
    "#     for i, a in enumerate(numpy.ix_(*arrays)):\n",
    "#         arr[...,i] = a\n",
    "#     return arr.reshape(-1, la)\n",
    "\n",
    "\n",
    "# # tracks_cartesian = cartesian_product(*(s_tracks_id * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaa6997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T03:12:33.651867Z",
     "start_time": "2021-10-16T03:12:33.639903Z"
    }
   },
   "outputs": [],
   "source": [
    "# for key, item in df_test.items():\n",
    "#     print(key)\n",
    "#     if key == 'tracks_id':\n",
    "#         print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define count_entries()\n",
    "# def count_entries(csv_file,c_size,colname):\n",
    "#     \"\"\"Return a dictionary with counts of\n",
    "#     occurrences as value for each key.\"\"\"\n",
    "    \n",
    "#     # Initialize an empty dictionary: counts_dict\n",
    "#     counts_dict = {}\n",
    "\n",
    "#     # Iterate over the file chunk by chunk\n",
    "#     for chunk in pd.read_csv(csv_file,chunksize=c_size):\n",
    "\n",
    "#         # Iterate over the column in DataFrame\n",
    "#         for entry in chunk[colname]:\n",
    "#             if entry in counts_dict.keys():\n",
    "#                 counts_dict[entry] += 1\n",
    "#             else:\n",
    "#                 counts_dict[entry] = 1\n",
    "\n",
    "#     # Return counts_dict\n",
    "#     return counts_dict\n",
    "\n",
    "# # Call count_entries(): result_counts\n",
    "# result_counts = count_entries('tweets.csv',10,'lang')\n",
    "\n",
    "# # Print result_counts\n",
    "# print(result_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ddbff7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-16T16:45:16.369Z"
    }
   },
   "outputs": [],
   "source": [
    "from numba import jit, cuda\n",
    "# from numba import cuda\n",
    "import numpy as np\n",
    "import code\n",
    "# to measure exec time\n",
    "from timeit import default_timer as timer\n",
    "  \n",
    "# normal function to run on cpu\n",
    "def func(a):                                \n",
    "    for i in range(10000000):\n",
    "        a[i]+= 1\n",
    "\n",
    "# function optimized to run on gpu \n",
    "cuda.jit(target =\"cuda\")                         \n",
    "code.interact(local=locals)\n",
    "def func2(a):\n",
    "    for i in range(100000000):\n",
    "        a[i]+= 1\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    n = 10000000                            \n",
    "    a = np.ones(n, dtype = np.float64)\n",
    "    b = np.ones(n, dtype = np.float32)\n",
    "      \n",
    "    start = timer()\n",
    "    func(a)\n",
    "    print(\"without GPU:\", timer()-start)    \n",
    "      \n",
    "    start = timer()\n",
    "    func2(a)\n",
    "    print(\"with GPU:\", timer()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e41699f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T16:49:46.034473Z",
     "start_time": "2021-10-16T16:49:45.090868Z"
    }
   },
   "outputs": [],
   "source": [
    "from numba import jit, cuda\n",
    "# from numba import cuda\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def mandel(x, y, max_iters):\n",
    "  \"\"\"\n",
    "  Given the real and imaginary parts of a complex number,\n",
    "  determine if it is a candidate for membership in the Mandelbrot\n",
    "  set given a fixed number of iterations.\n",
    "  \"\"\"\n",
    "  c = complex(x, y)\n",
    "  z = 0.0j\n",
    "  for i in range(max_iters):\n",
    "    z = z*z + c\n",
    "    if (z.real*z.real + z.imag*z.imag) >= 4:\n",
    "      return i\n",
    "\n",
    "  return max_iters\n",
    "\n",
    "@cuda.jit\n",
    "def mandel_kernel(min_x, max_x, min_y, max_y, image, iters):\n",
    "  height = image.shape[0]\n",
    "  width = image.shape[1]\n",
    "\n",
    "  pixel_size_x = (max_x - min_x) / width\n",
    "  pixel_size_y = (max_y - min_y) / height\n",
    "\n",
    "  startX = cuda.blockDim.x * cuda.blockIdx.x + cuda.threadIdx.x\n",
    "  startY = cuda.blockDim.y * cuda.blockIdx.y + cuda.threadIdx.y\n",
    "  gridX = cuda.gridDim.x * cuda.blockDim.x;\n",
    "  gridY = cuda.gridDim.y * cuda.blockDim.y;\n",
    "\n",
    "  for x in range(startX, width, gridX):\n",
    "    real = min_x + x * pixel_size_x\n",
    "    for y in range(startY, height, gridY):\n",
    "      imag = min_y + y * pixel_size_y \n",
    "      image[y, x] = mandel(real, imag, iters)\n",
    "\n",
    "gimage = np.zeros((1024, 1536), dtype = np.uint8)\n",
    "blockdim = (32, 8)\n",
    "griddim = (32,16)\n",
    "\n",
    "start = timer()\n",
    "d_image = cuda.to_device(gimage)\n",
    "mandel_kernel[griddim, blockdim](-2.0, 1.0, -1.0, 1.0, d_image, 20) \n",
    "d_image.to_host()\n",
    "dt = timer() - start\n",
    "\n",
    "print(\"Mandelbrot created on GPU in %f s\" % dt)\n",
    "\n",
    "imshow(gimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783ce0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale by row\n",
    "# min_max = MinMaxScaler()\n",
    "# tracks_rank['count_scaled'] = min_max.fit_transform(tracks_rank[[\"tracks_count\"]])\n",
    "\n",
    "track_normed = track_matrix / track_matrix.max(axis=0)\n",
    "track_normed_by_row = track_matrix / track_matrix.max(axis=1)\n",
    "\n",
    "delta = track_normed - track_normed_by_row\n",
    "print(delta.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb86b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphical visualization\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "# plt.imshow(track_matrix, interpolation='nearest', cmap=plt.cm.gist_heat)\n",
    "plt.imshow(track_normed, interpolation='nearest', cmap=plt.cm.Purples)\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359b24b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_detail(user_id, playlist_id):\n",
    "    l_artists = []\n",
    "    l_albums = []\n",
    "    l_tracks = []\n",
    "    l_popularity = []\n",
    "    l_artists_id = []\n",
    "    l_albums_id = []\n",
    "    l_tracks_id = []\n",
    "    \n",
    "    playlist = sp.user_playlist(user_id, playlist_id)\n",
    "    \n",
    "    for item in playlist['tracks']['items']:\n",
    "#         group = []\n",
    "#         group_id = []\n",
    "        for artist in item['track']['album']['artists']:\n",
    "            group.append(artist['name'])\n",
    "            group_id.append(artist['id'])\n",
    "        l_artists.append(group)\n",
    "        l_artists_id.append(group_id)\n",
    "        l_albums.append(item['track']['album']['name'])\n",
    "        l_tracks.append(item['track']['name'])\n",
    "        l_popularity.append(item['track']['popularity'])\n",
    "        \n",
    "        l_albums_id.append(item['track']['album']['id'])\n",
    "        l_tracks_id.append(item['track']['id'])\n",
    "        \n",
    "    playlist_details = zip(user_id, playlist_id, l_artists, l_albums, l_tracks, l_popularity, l_artists_id, l_albums_id, l_tracks_id)\n",
    "    return playlist_details;\n",
    "\n",
    "# user_id, playlist_id, l_artists, l_albums, l_tracks, l_popularity, l_artists_id, l_albums_id, l_tracks_id = get_playlist_detail('spotify', '37i9dQZF1DWXjlWxUbm84A')\n",
    "# user_id, playlist_id, l_artists, l_albums, l_tracks, l_popularity, l_artists_id, l_albums_id, l_tracks_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad08467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = df_test[['tracks_id','tracks']]\n",
    "# print(temp)\n",
    "\n",
    "# for i, a in enumerate(temp['tracks_id']):\n",
    "#     print(i)\n",
    "#     print(a)\n",
    "\n",
    "# for i in df_test:\n",
    "#     print(i)\n",
    "\n",
    "# print(temp['tracks'][1])\n",
    "# df_test[['tracks','tracks_id','popularity']].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4227200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_id_name(data, id_column, name_column):\n",
    "    dict_id_name = dict()\n",
    "\n",
    "    for i, item in enumerate(data[[id_column, name_column]][id_column]):\n",
    "        dict_id_name = dict(\n",
    "            zip(item, data[[id_column, name_column]][name_column][i]))\n",
    "    return dict_id_name\n",
    "\n",
    "\n",
    "# dict_id_name(df_test,'tracks_id','tracks')\n",
    "\n",
    "\n",
    "def dict_tracks(data):\n",
    "    dict_id_name = dict()\n",
    "\n",
    "    for i, item in enumerate(data['tracks_id']):\n",
    "#     for item in data['tracks_id']:\n",
    "        print(i)\n",
    "#         print(item)\n",
    "#         print(data.iloc[i])\n",
    "        \n",
    "        for k in item:\n",
    "            print(k)\n",
    "        \n",
    "        \n",
    "#         print(\n",
    "#             data[[\n",
    "#                 'tracks', 'popularity', 'artists_id', 'artists', 'albums_id',\n",
    "#                 'albums'\n",
    "#             ]].iloc[i])\n",
    "#         dict_id_name = dict(zip(item, list(data[['tracks']].iloc[i])))\n",
    "#         dict_id_name1 = dict(zip(item, data[['popularity']].iloc[i]))\n",
    "#         dict_id_name2 = dict(zip(item, data[['artists_id']].iloc[i]))\n",
    "#         dict_id_name3 = dict(zip(item, data[['artists']].iloc[i]))\n",
    "#         dict_id_name4 = dict(zip(item, data[['albums_id']].iloc[i]))\n",
    "#         dict_id_name5 = dict(zip(item, data[['albums']].iloc[i]))\n",
    "\n",
    "#         for grp in groups:\n",
    "#             #do some calcs to get a dataframe called 'df'\n",
    "#             frames[grp] = df\n",
    "#         for k in item['tracks_id']:\n",
    "#             print(k)\n",
    "#             print(data[['tracks', 'popularity', 'artists_id', 'artists', 'albums_id',\n",
    "#                 'albums']].iloc[i][k])\n",
    "#             dict_id_name[k] = data[[\n",
    "#                 'tracks', 'popularity', 'artists_id', 'artists', 'albums_id',\n",
    "#                 'albums'\n",
    "#             ]].iloc[k]\n",
    "#             dict_id_name = dict(zip(item, list(data[['tracks']].iloc[i])))\n",
    "    return dict_id_name\n",
    "        \n",
    "\n",
    "print(dict_tracks(df_test[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "data_path = os.getcwd() + '\\\\data\\\\external\\\\raw_1_uid_pid.pkl'\n",
    "if os.path.exists(data_path):\n",
    "    data_path_2 = os.getcwd() + '\\\\data\\\\external\\\\raw_2_playlists.pkl'\n",
    "    if not(os.path.exists(data_path_2)):\n",
    "        with open(data_path, 'rb') as f:\n",
    "            uid_pid_raw = pickle.load(f)\n",
    "else:\n",
    "    n = 950 # max = 950\n",
    "    p_limit = 50 # limit of playlists max = 50\n",
    "\n",
    "    # list of all user ids (UID) and playlist ids (PID)\n",
    "    uid_pid_raw = []\n",
    "    \n",
    "    for y in range(2018,2022,1):\n",
    "        txt = 'year:' + str(y)\n",
    "        for i in range(0,n,1):\n",
    "            if i % 100 == 0: print(txt + ': ' + str(i) + '/' + str(n))\n",
    "            uid_pid = sp.search(q=txt, type='playlist', limit=p_limit, offset=i,market='US')\n",
    "            uid_pid_raw.append(uid_pid)\n",
    "    # Save the data\n",
    "    with open(data_path, 'wb') as f:\n",
    "        pickle.dump(playlist_raw, f)\n",
    "\n",
    "\n",
    "t_end = time.time()\n",
    "np.abs(t_start - t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083d9353",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "data_path = os.getcwd() + '\\\\data\\\\external\\\\raw_2_playlists.pkl'\n",
    "if os.path.exists(data_path):\n",
    "    print(\"Loading data...\")\n",
    "    data_path_2 = os.getcwd() + '\\\\data\\\\external\\\\split_1_playlists.pkl'\n",
    "    if not(os.path.exists(data_path_2)):\n",
    "        with open(data_path, 'rb') as f:\n",
    "            playlist_raw = pickle.load(f)\n",
    "else:\n",
    "    print(\"Requesting playlists - Spotipy\")\n",
    "#     playlist_raw = []\n",
    "\n",
    "#     for i, result in enumerate(uid_pid_raw):\n",
    "#         print(i)\n",
    "#         if i % 100 == 0: print(i)\n",
    "#         for user in result['playlists']['items']:\n",
    "#             pid = user['id']\n",
    "#             uid = user['owner']['id']\n",
    "#             try:\n",
    "#                 playlist = sp.user_playlist(user['id'],user['owner']['id'])\n",
    "#                 playlist_raw.append(playlist)\n",
    "#             except:\n",
    "#                 print(uid + \" \" + pid)\n",
    "                   \n",
    "   # Save the data\n",
    "#     with open(data_path, 'wb') as f:\n",
    "#         pickle.dump(playlist_raw, f)\n",
    "\n",
    "t_end = time.time()\n",
    "np.abs(t_start - t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddddace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "data_path = os.getcwd() + '\\\\data\\\\external\\\\raw_data.pkl'\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_pickle(data_path)\n",
    "else:\n",
    "#     print('ops')\n",
    "    n = 50\n",
    "    p_limit = 50 # limit of playlists max = 50\n",
    "\n",
    "    user_id = []\n",
    "    playlist_id = []\n",
    "    artist = []\n",
    "    album = []\n",
    "    track = []\n",
    "    popularity = []\n",
    "    artist_id = []\n",
    "    album_id = []\n",
    "    track_id = []\n",
    "\n",
    "    for i in uid_pid:\n",
    "        if i-1 % 100 == 0: print(i)\n",
    "        for user in result['playlists']['items']:\n",
    "            pid = user['id']\n",
    "            uid = user['owner']['id']\n",
    "#                 user_id.append(uid)\n",
    "#                 playlist_id.append(pid)\n",
    "            p_user_id, p_playlist_id, p_artist, p_album, p_track, p_popularity, p_artists_id, p_albums_id, p_tracks_id = unzip(get_playlist_detail(uid,pid))\n",
    "\n",
    "            user_id.append(p_user_id)\n",
    "            playlist_id.append(p_playlist_id)\n",
    "            artist.append(p_artist)\n",
    "            album.append(p_album)\n",
    "            track.append(p_track)\n",
    "            popularity.append(p_popularity)\n",
    "            artist_id.append(p_artist_id)\n",
    "            album_id.append(p_album_id)\n",
    "            track_id.append(p_track_id)\n",
    "#             if i-1 % 100 == 0: print('tot:' + str(len(playlist_id)))\n",
    "\n",
    "    # intialise data of lists.\n",
    "    data = {\n",
    "        'user_id': user_id,\n",
    "        'playlist_id': playlist_id,\n",
    "        'track_id': track_id,\n",
    "        'track': track,\n",
    "        'popularity': popularity,\n",
    "        'artist_id': artist_id,\n",
    "        'artist': artist,\n",
    "        'album_id': albums_id,\n",
    "        'album': album\n",
    "    }\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    df.head()\n",
    "\n",
    "    # Save the data\n",
    "    df.to_pickle(data_path)\n",
    "\n",
    "t_end = time.time()\n",
    "np.abs(t_start - t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff83221",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_tracks_id = single_list(df['tracks_id'])\n",
    "s_tracks = single_list(df['tracks'])\n",
    "s_popularity = single_list(df['popularity'])\n",
    "\n",
    "s_artists = single_list_nested(df['artists'])\n",
    "s_artists_id = single_list_nested(df['artists_id'])\n",
    "\n",
    "s_albums = single_list(df['albums'])\n",
    "s_albums_id = single_list(df['albums_id'])\n",
    "\n",
    "data = {\n",
    "    'tracks_id': s_tracks_id,\n",
    "    'tracks': s_tracks,\n",
    "    'popularity': s_popularity\n",
    "}\n",
    "df_track = pd.DataFrame(data)\n",
    "# print(df_track.head())\n",
    "\n",
    "data = {\n",
    "    'artists_id': s_artists_id,\n",
    "    'artists': s_artists\n",
    "}\n",
    "df_artist = pd.DataFrame(data)\n",
    "# print(df_artist.head())\n",
    "\n",
    "\n",
    "data = {\n",
    "    'albums_id': s_albums_id,\n",
    "    'albums': s_albums\n",
    "}\n",
    "df_album = pd.DataFrame(data)\n",
    "# print(df_album.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410e374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_rank = df_track.groupby(['tracks_id','tracks']).agg(\n",
    "    popularity=('popularity','max'),\n",
    "    tracks_count=('tracks_id','count')\n",
    "    )\n",
    "\n",
    "min_max = MinMaxScaler()\n",
    "tracks_rank['count_scaled'] = min_max.fit_transform(tracks_rank[[\"tracks_count\"]])\n",
    "\n",
    "tracks_rank[\"rank\"] = tracks_rank['tracks_count'].rank(method='average',ascending=False)\n",
    "\n",
    "tracks_rank = tracks_rank.sort_values('tracks_count',ascending=False)\n",
    "\n",
    "tracks_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f770a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "album_rank = df_album.groupby(['albums_id','albums']).agg(album_count=('albums_id','count'))\n",
    "\n",
    "min_max = MinMaxScaler()\n",
    "album_rank['count_scaled'] = min_max.fit_transform(album_rank[[\"album_count\"]])\n",
    "\n",
    "album_rank[\"rank\"] = album_rank['album_count'].rank(method='average',ascending=False)\n",
    "\n",
    "album_rank = album_rank.sort_values('album_count',ascending=False)\n",
    "\n",
    "album_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e89c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist.head\n",
    "artist_rank = df_artist.groupby(['artists_id','artists']).agg(artist_count=('artists_id','count'))\n",
    "\n",
    "min_max = MinMaxScaler()\n",
    "artist_rank['count_scaled'] = min_max.fit_transform(artist_rank[[\"artist_count\"]])\n",
    "\n",
    "artist_rank[\"rank\"] = artist_rank['artist_count'].rank(method='average',ascending=False)\n",
    "\n",
    "artist_rank = artist_rank.sort_values('artist_count',ascending=False)\n",
    "\n",
    "artist_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b73368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, item in df_test.items():\n",
    "#     print(key)\n",
    "#     if key == 'tracks_id':\n",
    "#         print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d50128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define count_entries()\n",
    "# def count_entries(csv_file,c_size,colname):\n",
    "#     \"\"\"Return a dictionary with counts of\n",
    "#     occurrences as value for each key.\"\"\"\n",
    "    \n",
    "#     # Initialize an empty dictionary: counts_dict\n",
    "#     counts_dict = {}\n",
    "\n",
    "#     # Iterate over the file chunk by chunk\n",
    "#     for chunk in pd.read_csv(csv_file,chunksize=c_size):\n",
    "\n",
    "#         # Iterate over the column in DataFrame\n",
    "#         for entry in chunk[colname]:\n",
    "#             if entry in counts_dict.keys():\n",
    "#                 counts_dict[entry] += 1\n",
    "#             else:\n",
    "#                 counts_dict[entry] = 1\n",
    "\n",
    "#     # Return counts_dict\n",
    "#     return counts_dict\n",
    "\n",
    "# # Call count_entries(): result_counts\n",
    "# result_counts = count_entries('tweets.csv',10,'lang')\n",
    "\n",
    "# # Print result_counts\n",
    "# print(result_counts)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
